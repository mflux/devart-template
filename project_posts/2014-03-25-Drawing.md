One of the first things I wanted to improve upon Manifest was allow the user to literally draw anything, and have that drawing become meaningful.

The first step is allowing the user to draw at all, which I'll outline below.

##Strokes and Lines

We define a currentStroke that's essentially a THREE.js Mesh. The reason I chose THREE.js is numerous, but this project was for learning the API, and figuring out if I could do something dynamic (eg non static meshes) within the framework.

As mentioned, the library I'll be using to draw things on screen is THREE.js by Mr Doob.

[Three.js](https://github.com/mrdoob/three.js/ "Three.js")

```
//	a penstroke object contains points about each pen stroke and the ability to add to each stroke
function PenStroke(){
	//	maximum number of vertices in a single stroke
	this.maxPenPoints = 400;
	this.geometry = new THREE.Geometry();
	this.geometry.dynamic = true;

	//	make an empty # of vertices, hidden away at the top left
	//	and make it invisible!

	for( var i=0; i<this.maxPenPoints; i++){
		this.geometry.vertices.push( new THREE.Vertex( new THREE.Vector3(0,0,0) ) );	
		// this.geometry.colors.push( new THREE.Color(0x000000) );
	}			
	this.mesh = new THREE.Line( this.geometry, penMat, THREE.LineStrip);

	drawnMesh.add(this.mesh);			

	//	... etc
	
	this.paint = function( drawX, drawY ){
		//	sets the position of the next vertex we're drawing		
	}    	

	this.finishPainting = function(){
		//	do some cleanup and culling of verts					
	
		//	cut down the number of verts to exactly what's drawn
		this.geometry.vertices = this.geometry.vertices.splice( 0,this.paintIndex );				

		//	deallocate the mesh object
		drawnMesh.remove( this.mesh );

		//	this kills the mesh...
		// renderer.deallocateObject( this.mesh );

		//	make a new one and insert it to drawnMesh
		this.mesh = new THREE.Line( this.geometry, penMat, THREE.LineStrip );

		//	what does this do?
		this.geometry.__webglLineCount = this.paintIndex;

		//	the new vert count...
		// console.log( this.mesh.geometry.vertices.length );

		drawnMesh.add( this.mesh );
	}
}
```

So, whenever we're touching the canvas (eg click and drag on it) we "paint" a vertex and set it to visible. 

```
	currentStroke.paint( mouseX - width/2, mouseY - pressY );
```

![Drawing Lines](project_images/drawinglines.gif?raw=true "Drawing Lines")

So far so good. However, deep-sea creatures are in general symmetrical across their spine. Let's make that happen.

```
	currentStroke.paint( mouseX - width/2, mouseY - pressY );
	mirroredStroke.paint( width/2 - mouseX, mouseY - pressY );
```

Notice how I'm using a mirrored geometry, rather than combining it all into one single geometry. This is because ultimately the creature data-type is going to be stored, and I only want to store the user's line-stroke, rather than the entire creature geometry (mirrored and all).

![Mirrored Lines](project_images/mirroredlines.gif?raw=true "Mirrored Lines")

So, why have I done all this in vectors, rather than say... created something so I could paint on canvas? Wouldn't I be wasting a lot of effort trying to render this with vertices?

Well here's the thing, if I wanted to replicate this form repeatedly, and then scale it, a raster image would have been pretty ugly. Here's what it would have looked like had I done everything as pixel data, rather than vector data.

![Raster Lines](project_images/rastermockup.png?raw=true "Raster Lines")

This won't do at all! The lines get all fuzzy, the pixel data starts deteriorating, and rotating it would have looked quite bad. In addition, if I wanted to modify this shape somehow, or render it in some other way, I would have fewer choices if I kept the drawing as bitmap data.

Here it is with repeated drawings, as vector data.

![Repeated Lines](project_images/repeateddrawings.png?raw=true "Repeated Lines")

I've skipped a step. Notice how the drawings are changing shape as we clone it downwards. This is the power of having vector data, we can scale it "for free" in vector, without losing detail. We can do all sorts of stuff to it, like skew, squash, etc.

![Controlled Cloning](project_images/controlled_cloning.gif?raw=true "Controlled Cloning")

By using this library

[Dat.GUI](https://code.google.com/p/dat-gui/ "Dat.GUI")

we now have some seriously awesome sliders to play with our variables. Whenever the sliders change, we re-compose the entire creature via cloning, and have a few settings for how much scaling is applied per clone, following some basic rules:

```
function composeSegmentProportion( segmentMesh, iteration ){

	//	space the segments down, but closer and closer together
	segmentMesh.position.y += Math.log( 1 + iteration / (1 + (40-controls.spacing))) * 650;

	//	scale the segments smaller and smaller as it goes down the body
	segmentMesh.scale.x = 1 - 0.01 * iteration * iteration * controls.shrinkage;
	segmentMesh.scale.y = 1 - 0.005 * iteration * iteration * controls.shrinkage;

	//	set a minimum segment sizew
	if(segmentMesh.scale.x < 0.02)
		segmentMesh.scale.x = 0.02;
	if(segmentMesh.scale.y < 0.02)
		segmentMesh.scale.y = 0.02;			    	
}
```

I hope you enjoyed this update. Tomorrow I'll write about the data structure, and procedural animation!
